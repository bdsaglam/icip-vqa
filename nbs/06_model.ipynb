{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class BaselineSTM(Module):\n",
    "    def __init__(self, arch, n_out, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(create_body(arch, pretrained=pretrained))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.head = TimeDistributed(create_head(n_features, n_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_map = self.encoder(torch.stack(x, dim=1))\n",
    "        return self.head(feature_map).mean(dim=1)\n",
    "   \n",
    "    @staticmethod\n",
    "    def splitter(model): \n",
    "        return [params(model.encoder), params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class BaselineMTM(Module):\n",
    "    def __init__(self, arch, n_distortion, n_sev, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(create_body(arch, pretrained=pretrained))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.head = TimeDistributed(create_head(n_features, n_distortion + n_sev))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_map = self.encoder(torch.stack(x, dim=1))\n",
    "        out = self.head(feature_map).mean(dim=1)\n",
    "        return [out[:, :self.n_distortion], out[:, self.n_distortion:]]\n",
    "   \n",
    "    @staticmethod\n",
    "    def splitter(model): \n",
    "        return [params(model.encoder), params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MultiScaleBackbone(Module):\n",
    "    def __init__(self, arch, pretrained=True):\n",
    "        store_attr()\n",
    "        self.backbone = create_body(arch, pretrained=pretrained)\n",
    "        self.hooks = hook_outputs(list(self.backbone.children())[4:-1], detach=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat_map_last = self.backbone(x)\n",
    "        feat_maps = self.hooks.stored\n",
    "        return torch.cat([AdaptiveConcatPool2d()(fm) for fm in [*feat_maps, feat_map_last]], dim=1)\n",
    "    \n",
    "class MultiScaleMTM(Module):\n",
    "    def __init__(self, arch, n_distortion, n_sev, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(MultiScaleBackbone(arch, pretrained=pretrained))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.head = TimeDistributed(create_head(n_features, n_distortion + n_sev))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.stack(x, dim=1)\n",
    "        feature_map = self.encoder(x)\n",
    "        out = self.head(feature_map).mean(dim=1)\n",
    "        return [out[:, :self.n_distortion], out[:, self.n_distortion:]]\n",
    "   \n",
    "    @staticmethod\n",
    "    def splitter(model): \n",
    "        return [params(model.encoder), params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SequenceSTM(Module):\n",
    "    def __init__(self, arch, n_out, num_rnn_layers=1, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(nn.Sequential(\n",
    "            create_body(arch, pretrained=pretrained), \n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            Flatten()\n",
    "        ))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.rnn = nn.LSTM(n_features, n_features, num_layers=num_rnn_layers, batch_first=True)\n",
    "        self.head = create_head(num_rnn_layers * n_features, n_out)[2:]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(torch.stack(x, dim=1))\n",
    "        bs = x.shape[0]\n",
    "        _, (h, _) = self.rnn(x)\n",
    "        return self.head(h.view(bs, -1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def splitter(model):\n",
    "        return [params(model.encoder), params(model.rnn) + params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SequenceMTM(Module):\n",
    "    def __init__(self, arch, n_distortion, n_sev, num_rnn_layers=1, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(nn.Sequential(\n",
    "            create_body(arch, pretrained=pretrained), \n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            Flatten()\n",
    "        ))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.rnn = nn.LSTM(n_features, n_features, num_layers=num_rnn_layers, batch_first=True)\n",
    "        self.head = create_head(num_rnn_layers * n_features, n_out)[2:]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(torch.stack(x, dim=1))\n",
    "        bs = x.shape[0]\n",
    "        _, (h, _) = self.rnn(x)\n",
    "        out = self.head(h.view(bs,-1))\n",
    "        return out[:, :self.n_distortion], out[:, self.n_distortion:]\n",
    "    \n",
    "    @staticmethod\n",
    "    def splitter(model):\n",
    "        return [params(model.encoder), params(model.rnn) + params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MultiHeadMTM(Module):\n",
    "    def __init__(self, arch, n_distortion, n_sev, pretrained=True):\n",
    "        store_attr()\n",
    "        self.encoder = TimeDistributed(create_body(arch, pretrained=pretrained))\n",
    "        n_features = dummy_eval(self.encoder.module, (224, 224)).shape[1]\n",
    "        self.common_head = TimeDistributed(nn.Sequential(create_head(n_features, n_features), nn.ReLU()))\n",
    "        self.dis_head = TimeDistributed(LinBnDrop(n_features, n_distortion))\n",
    "        self.sev_head = TimeDistributed(LinBnDrop(n_features, n_sev))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_map = self.encoder(torch.stack(x, dim=1))\n",
    "        h = self.common_head(feature_map)\n",
    "        out_dis = self.dis_head(h).mean(dim=1)\n",
    "        out_sev = self.sev_head(h).mean(dim=1)\n",
    "        return [out_dis, out_sev]\n",
    "   \n",
    "    @staticmethod\n",
    "    def splitter(model): \n",
    "        return [params(model.encoder), params(model.common_head) + params(model.dis_head) + params(model.sev_head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "bs = 2\n",
    "n = 5\n",
    "ndis, nsev = 18, 4\n",
    "mhmtm = MultiHeadMTM(resnet18, ndis, nsev, False)\n",
    "x = [torch.rand(bs, 3, 224, 224) for i in range(n)]\n",
    "y1, y2 = mhmtm(x)\n",
    "assert y1.shape == torch.Size([bs, ndis])\n",
    "assert y2.shape == torch.Size([bs, nsev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vqa')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
